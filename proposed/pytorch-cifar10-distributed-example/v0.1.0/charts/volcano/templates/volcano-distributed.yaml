apiVersion: batch.volcano.sh/v1alpha1
kind: Job
metadata:
  name: pytorch-ringallreduce
  namespace: {{ .Release.Namespace }}
  labels:
    "volcano.sh/job-type": "Pytorch"
spec:
  minAvailable: {{ .Values.minMember }}
  schedulerName: {{ .Values.schedulername }}
  plugins:
    env: []
    svc: []
  policies:
    - event: PodEvicted
      action: RestartJob
  tasks:
    - replicas: {{ .Values.worker.replicas }}
      name: worker
      template:
        spec:
          containers:
            - command:
                - sh
                - -c
                - python /code/main.py --backend {{ .Values.global.training.backend }} --init-method tcp://pytorch-ringallreduce-worker-0.pytorch-ringallreduce:23456 --world-size {{ .Values.global.training.worldsize }} --rank ${VK_TASK_INDEX} --arch {{ .Values.global.training.arch }} --epochs {{ .Values.global.training.epochs }} --batch-size {{ .Values.global.training.batchsize }} --learning-rate {{ .Values.global.training.learningrate }}
              image: "{{ .Values.image.job.name }}:{{ .Values.image.job.tag }}"
              name: worker
              securityContext:
                capabilities:
                  add: [ "IPC_LOCK" ]
              ports:
                - containerPort: 23456
                  name: job-port
              resources:
                limits:
                    {{- if eq .Values.global.gpu.enabled true -}}
                    {{ .Values.global.gpu.name }}: {{ .Values.global.gpu.num }}
                    {{- end -}}
                    {{- if eq .Values.global.rdma.enabled true -}}
                    {{ .Values.global.rdma.name }}: 1
                    {{- end -}}
          restartPolicy: OnFailure